####################	README   #####################

Author: Petros Mitseas, pmitseas@auth.gr

Για απορίες επικοινωνήστε στο παραπάνω e-mail.

Για να λειτουργήσει ο κώδικας πρέπει να υπάρχει εγκατεστημένο
το πρόγραμμα Mujoco. Στο αρχείο muscle.py στην γραμμή 7,
πρέπει να οριστεί το path στο οποίο βρίσκονται τα αρχεία
του mujoco. Επίσης στη γραμμη 14 πρέπει να οριστεί το path για το xml αρχείο hello_world (βλεπε παρακάτω).

Άλλα dependances: python3, NumPy, SciPy, pulp, pyhull,
		  MPI, pandas, bisect

######################################################

ΠΕΡΙΓΡΑΦΗ ΑΡΧΕΙΩΝ

hello_world5.xml: Το μοντέλο του ρομπότ και του περιβάλλοντος σε μορφή XML που αναγνωρίζει ο Mujoco (mujoco.org). Στον κώδικα κάνουμε comment/uncomment τα κομμάτια που μοντελοποιούν τα αντικείμενα, ώστε να επιλέξουμε σε ποιό αντικείμενο θα εκπαιδευτεί το ρομπότ.

RL_environment: Εδώ υπάχρχουν οι high level κλάσεις για το περιβάλλον και το ρομπότ. Συγκεκριμένα υπάρχουν οι συναρτήσεις step/reset που χρησιμοποιούνται όπως στο OpenAI Gym. Ο κώδικας κάνει χρήση των αρχείων hello_world5.xml και muscle.py. Επίσης εδώ γίνεται η μετατροπή των μεταβλητών σε καταστάσεις, χρησιμοποιώντας την μέθοδο Tile Coding (φάκελος Tiles).

muscle.py: Όλο το low level κομμάτι του ρομπότ. Περιλαμβάνει τα υποσυστήματα Motion Planner (ή Path Planner), και Robot Controller. Για τον ρόλο των υποσυστημάτων ανατρέξτε στην διπλωματική εργασία "Ενισχυτική Μάθηση στη Ρομποτική Λαβή - Πέτρος Μητσέας". Το module Robot Controller, περιέχει ακόμα συναρτήσεις που επιτελούν την συλλογή των δεδομένων από τον προσομοιωτή: Δυνάμεις, θέση και προσανατολισμός του ρομπότ κλπ.

RL_brain.py: Εδώ υπάρχει μια συλλογή από αλγορίθμους της ενισχυτικής μάθησης. Οι κλάσεις είναι γραμμένες σύμφωνα με τα πρότυπα του OpenAi Gym. By default ο αλγόριθμος που χρησιμοποιείται είναι ο expected SARSA με Tile Coding (βλ. Introduction to Reinforcement Learning, Sutton)

SingleAgent.py: Είναι το εκτελέσιμο αρχείο. Στο αρχείο αυτό υπάρχει η κεντρική loop που ακολουθεί το ρομπότ κάτω από την συνάρτηση run_simulation.Στο αρχείο αυτό κάτω από την ενότητα "MAIN SCRIPT" ρυθμίζονται οι παράμετροι της προσομοίωσης.

RL_Tests.py: Εδώ υπάρχουν κλάσεις που επιτελούν τη συλλογή δεδομένων για debugging και επεξεργασία με άλλα προγράμματα πχ matlab. Προτείνουμε στον αναγνώστη να υλοποιήσει τις δικές του συναρτήσεις καθώς μπορεί να επιθυμεί διαφορετικά δεδομένα από αυτά που συλλέξαμε εμείς στα πλαίσια της διπλωματικής.

MultiAgent.py: Εκτελέσιμο αρχείο όταν επιθυμούμε να τρέξουμε παράλληλη μάθηση πολλών ρομπότ. Απαιτείται εγκατεστημένο το framework MPI.

MPIConfig.py: Configuration αρχείο. Αν επιθυμούμε να τρέξουμε το SingleAgent.py τότε πρέπει η μεταβλητή "Single_Agent" να τίθεται σε 1. Ειδάλλως αν πρόκειται να τρέξουμε το MultiAgent.py θέτουμε τη μεταβλητή 0.


###################### ΠΩΣ ΤΡΕΧΟΥΜΕ ΤΗΝ ΠΡΟΣΟΜΟΙΩΣΗ #########################

Για να τρέξουμε την προσομοίωση για έναν πράκτορα, μεταβαίνουμε στον φάκελο όπου βρίσκεται το αρχείο SingleAgent.py και γράφουμε σε Terminal:

python3 SingleAgent.py


Για να τρέξουμε την προσομοίωση για πολλούς πράκτορες, αφού έχουμε ρυθμίσει την μεταβλητή "Single_Agent" στο αρχείο MPIConfig.py σε 0, γράφουμε το παρακάτω

mpiexec -n N python3 MultiAgent.py

όπου N = 2,... ο αριθμός των διεργασιών. Δεδομένου ότι ένα proccess είναι αφιερωμένο στην επεξεργασία των δεδομένων, ο αριθμός των πρακτόρων είναι ίσος με N-1.
